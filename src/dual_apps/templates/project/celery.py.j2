"""
Celery configuration for {{ project_name }}.
Generated by dual-apps v{{ version }}

Setup:
    1. Start Redis: docker-compose up -d redis
    2. Start Celery worker: celery -A {{ project_name }} worker -l INFO
    3. Start Celery beat: celery -A {{ project_name }} beat -l INFO
"""

import os
from celery import Celery

# Set default Django settings
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "{{ project_name }}.settings")

app = Celery("{{ project_name }}")

# Using a string here means the worker doesn't have to serialize
# the configuration object to child processes.
app.config_from_object("django.conf:settings", namespace="CELERY")

# Celery Configuration
app.conf.update(
    # Broker settings (Redis)
    broker_url=os.environ.get("CELERY_BROKER_URL", "redis://localhost:6379/0"),
    result_backend=os.environ.get("CELERY_RESULT_BACKEND", "redis://localhost:6379/0"),

    # Task settings
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,

    # Task execution settings
    task_acks_late=True,
    task_reject_on_worker_lost=True,

    # Worker settings
    worker_prefetch_multiplier=1,
    worker_concurrency=4,

    # Result settings
    result_expires=3600,  # 1 hour

    # Beat schedule
    beat_schedule={
        # Example scheduled task
        # "cleanup-old-records": {
        #     "task": "apps.{{ apps[0] }}.tasks.cleanup_old_records",
        #     "schedule": crontab(hour=3, minute=0),  # Daily at 3 AM
        # },
    },
)

# Load task modules from all registered Django apps.
app.autodiscover_tasks()


@app.task(bind=True, ignore_result=True)
def debug_task(self):
    """Debug task to verify Celery is working."""
    print(f"Request: {self.request!r}")
